{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5100 Foundations of Artificial Intelligence Spring 2018  \n",
    "Project on developing a machine learning model to classify wikipedia discussion comments as whether they contain a\n",
    "personal attack or not.  \n",
    "The following code is implemented in jupyter notebook - python version 3.    \n",
    "By Survi Satpathy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for code execution\n",
    "1. Text cleanup  - Removal of special characters like puntuations, URL , digits, extra spaces and newline      characters\n",
    "2. Feature Extraction - Tokeninzing and tranforming the bag of words to useful features to model a classifier\n",
    "3. List of Classifiers - Selecting a list of classfiers to learn on the extracted features. Comparing the\n",
    " performance of each based on ROC AUC score\n",
    "4. Cross Validation - Performing cross validation on the classifiers by making use of the dev data set to choose the best classifier\n",
    "5. Parameter tunning - Perform grid search and randomized search on the selected classfier to know the best set of parameters which       improve the ROC AUC score of the chosen classifier\n",
    "6. Final Metrics - Testing the performance of the best classifier(used it;s the list of best parameters) on the testing data set. Evaluting it's ROC AUC score, Confusion metrics,Classification Report,Precision, Recall, F1 score and Support\n",
    "7. Conclusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import string\n",
    "import re\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier,Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download annotated comments and annotations\n",
    "\n",
    "# ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7554634' \n",
    "# ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7554637' \n",
    "\n",
    "\n",
    "# def download_file(url, fname):\n",
    "#     urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "                \n",
    "# download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "# download_file(ANNOTATIONS_URL, 'attack_annotations.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations = pd.read_csv('attack_annotations.tsv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115864"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations['rev_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# labels a comment as an atack if the majority of annoatators did so\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join labels and comments\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text clean up methods tried removing punctuations , digits, URL , multiple white spaces, newline and tab\n",
    "# Also applied English stop words removal technique but this did not improve performance. So removed it\n",
    "# Text cleanup methods kept in the final code - removing punctuations , digits, URL, multiple white spaces,\n",
    "# newline and tab\n",
    "# This is the first optimization technique applied on data preprocessing and filtering\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: re.sub(r\"[!#$%&'()*+,-./:;<=>?@^_`{|}~\\d+]+\\ *\", \" \", x))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: ' '.join(x.split()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rev_id\n",
       "801279                           Iraq is not good USA is bad\n",
       "2702703    fuck off you little asshole If you want to tal...\n",
       "4632658           i have a dick its bigger than yours hahaha\n",
       "6545332    renault you sad little bpy for driving a renau...\n",
       "6545351    renault you sad little bo for driving a renaul...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.query('attack')['comment'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial trial of all classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: CalibratedClassifierCV(base_estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0),\n",
      "            cv=3, method='sigmoid')\n",
      "precision recall: (0.8874501992031872, 0.6465892597968069, 0.7481108312342569, None)\n",
      "true neg:  20196  false pos:  226  false neg:  974  true pos:  1782\n",
      "Test ROC AUC: 0.965\n",
      "Time taken 216.07876348495483 seconds \n",
      "-----------------------------------------------------------------------------------------\n",
      "Classifier: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "precision recall: (0.9126406353408338, 0.5003628447024674, 0.6463557534567612, None)\n",
      "true neg:  20290  false pos:  132  false neg:  1377  true pos:  1379\n",
      "Test ROC AUC: 0.951\n",
      "Time taken 66.67152190208435 seconds \n",
      "-----------------------------------------------------------------------------------------\n",
      "Classifier: MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "precision recall: (0.9878048780487805, 0.05878084179970972, 0.11095890410958903, None)\n",
      "true neg:  20420  false pos:  2  false neg:  2594  true pos:  162\n",
      "Test ROC AUC: 0.830\n",
      "Time taken 60.19262218475342 seconds \n",
      "-----------------------------------------------------------------------------------------\n",
      "Classifier: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "precision recall: (0.9497549019607843, 0.28120464441219156, 0.43393057110862254, None)\n",
      "true neg:  20381  false pos:  41  false neg:  1981  true pos:  775\n",
      "Test ROC AUC: 0.877\n",
      "Time taken 102.06287956237793 seconds \n",
      "-----------------------------------------------------------------------------------------\n",
      "Classifier: CalibratedClassifierCV(base_estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=1600, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False),\n",
      "            cv=3, method='sigmoid')\n",
      "precision recall: (0.7941701368233195, 0.4843976777939042, 0.6017579445571332, None)\n",
      "true neg:  20076  false pos:  346  false neg:  1421  true pos:  1335\n",
      "Test ROC AUC: 0.913\n",
      "Time taken 64.05413365364075 seconds \n",
      "-----------------------------------------------------------------------------------------\n",
      "Classifier: CalibratedClassifierCV(base_estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='modified_huber', max_iter=1600,\n",
      "       n_iter=None, n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False),\n",
      "            cv=3, method='sigmoid')\n",
      "precision recall: (0.8668341708542714, 0.6259071117561683, 0.7269279393173199, None)\n",
      "true neg:  20157  false pos:  265  false neg:  1031  true pos:  1725\n",
      "Test ROC AUC: 0.960\n",
      "Time taken 67.03399610519409 seconds \n",
      "-----------------------------------------------------------------------------------------\n",
      "Classifier: CalibratedClassifierCV(base_estimator=Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      max_iter=1600, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
      "      shuffle=True, tol=0.001, verbose=0, warm_start=False),\n",
      "            cv=3, method='sigmoid')\n",
      "precision recall: (0.9052863436123348, 0.5965166908563135, 0.7191601049868768, None)\n",
      "true neg:  20250  false pos:  172  false neg:  1112  true pos:  1644\n",
      "Test ROC AUC: 0.958\n",
      "Time taken 70.09481739997864 seconds \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# This cell demonstrates the performance of various classifiers on the test\n",
    "# data set before applying cross validation technique. \n",
    "\n",
    "# Training and test set used for inital test of all classifiers\n",
    "train_all_classifiers = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "\n",
    "# list of classifiers to choose from \n",
    "clf_list = [\n",
    "            CalibratedClassifierCV(LinearSVC()),\n",
    "            LogisticRegression(),\n",
    "            MultinomialNB(),\n",
    "            RandomForestClassifier(),\n",
    "            CalibratedClassifierCV(SGDClassifier(loss='log',max_iter=1600,tol=1e-3)),# SGD classifier \n",
    "                                                             # requires passing of paramters like max_iter and tol. \n",
    "            CalibratedClassifierCV(SGDClassifier(loss='modified_huber',max_iter=1600,tol=1e-3)),\n",
    "            CalibratedClassifierCV(Perceptron(max_iter=1600,tol=1e-3)),# Perceptron classifier requires \n",
    "                                                                # passing of parameters max_iter & tol\n",
    "            MLPClassifier()\n",
    "            ]\n",
    "\n",
    "# features include - unigram and bigrams of words or chars. Adding both improved the performance of the code\n",
    "# so included both in the final version\n",
    "for classifier in clf_list:\n",
    "    start_time = time.time()\n",
    "    clf = Pipeline([\n",
    "        ('vect', FeatureUnion([ \n",
    "            # Applied a combination of char and word tokenization using CountVectorizer and TfidfVectorizer\n",
    "            # After trial and testing applied max_feature as 75000, \n",
    "            # decode_error when set to 'replace'/'ignore' performed better than 'strict' \n",
    "            # This is the 3rd optimization technique applied.\n",
    "            ('count',CountVectorizer(max_features = 75000, ngram_range = (1,2),analyzer='word',\n",
    "                                     decode_error='replace')),\n",
    "            ('count1',CountVectorizer(max_features = 75000, ngram_range = (1,2),analyzer='char',\n",
    "                                     decode_error='replace')),\n",
    "            ('tfvect',TfidfVectorizer(max_features = 75000,norm = 'l2',analyzer='word',\n",
    "                                    decode_error='replace')),\n",
    "            ('tfvect1',TfidfVectorizer(max_features = 75000,norm = 'l2',analyzer='char',\n",
    "                                      decode_error='ignore'))\n",
    "        ])),\n",
    "        ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "        ('clf',  classifier)])\n",
    "    \n",
    "    print('Classifier:',classifier)\n",
    "    clf=clf.fit(train_all_classifiers['comment'], train_all_classifiers['attack'])\n",
    "    # This is the roc_auc score of the classifier before applying cross validation technique \n",
    "    auc = roc_auc_score(test_comments['attack'], clf.predict_proba(test_comments['comment'])[:, 1])\n",
    "    predict = clf.predict(test_comments['comment'])\n",
    "    # Claculation of Performance Metric : precision_recall\n",
    "    precision_recall=precision_recall_fscore_support(test_comments['attack'], predict, average='binary')\n",
    "    # Claculation of Performance Metric : confusion_matrix\n",
    "    tn, fp, fn, tp=confusion_matrix(test_comments['attack'],predict).ravel()\n",
    "\n",
    "    print('precision recall:',precision_recall)\n",
    "    print('true neg: ',tn,' false pos: ',fp,' false neg: ',fn,' true pos: ',tp)\n",
    "\n",
    "    print('Test ROC AUC: %.3f' %auc)\n",
    "    print(\"Time taken %s seconds \" % (time.time() - start_time))\n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance metrics before Cross Validation\n",
    "By comparing the ROC AUC score of the various classifiers listed above **LinearSVC** has been found to be   \n",
    "the best so far. Let us now calculate the values of various performance metrics on the LinearSVC.   \n",
    "This step has only been done to compare the final result metrics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision recall: (0.8921326076199901, 0.6542089985486212, 0.7548670713837138, None)\n",
      "true neg:  20204  false pos:  218  false neg:  953  true pos:  1803\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Multiple performance metrics are captured below\n",
    "# Looking at Confusion matrix we can tell how many of the true positives where classified correctly from\n",
    "# the test set. The classification report gives the Precision, Recall, F1 score and support values from the\n",
    "# test set. This gives an idea of how well the classifier performed. \n",
    "\n",
    "# Training and test set used for inital test of all classifiers\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "clf = Pipeline([\n",
    "        # Feature Union of the previously used combination of CountVectorizer and TfIdfVectorizer\n",
    "        # Applied sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
    "        ('vect', FeatureUnion([\n",
    "            ('count',CountVectorizer(max_features = 75000, ngram_range = (1,2),analyzer='word',\n",
    "                                     decode_error='replace')),\n",
    "            ('count1',CountVectorizer(max_features = 75000, ngram_range = (1,2),analyzer='char',\n",
    "                                     decode_error='replace')),\n",
    "            ('tfvect',TfidfVectorizer(max_features = 75000,norm = 'l2',analyzer='word',\n",
    "                                    decode_error='replace',sublinear_tf=True)),\n",
    "            ('tfvect1',TfidfVectorizer(max_features = 75000,norm = 'l2',analyzer='char',\n",
    "                                      decode_error='ignore',sublinear_tf=True))\n",
    "        ])),\n",
    "        ('tfidf', TfidfTransformer(norm = 'l2',sublinear_tf=True)),\n",
    "        # for the purpose of using roc_auc_score function on the learnt classifier, ClaiberatedClassifierCV() \n",
    "        # is used on LinearSVM along with its best params list\n",
    "        # This was required because by default LinearSVM does not have predict_proba() function\n",
    "        # Used LinearSVC as the classifier here as it showed the best result on the previous cell\n",
    "        ('clf',  CalibratedClassifierCV(LinearSVC()))])\n",
    "\n",
    "clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "predict = clf.predict(test_comments['comment'])\n",
    "# Claculation of Performance Metric : precision_recall\n",
    "precision_recall=precision_recall_fscore_support(test_comments['attack'], predict, average='binary')\n",
    "# Claculation of Performance Metric : confusion_matrix\n",
    "tn, fp, fn, tp=confusion_matrix(test_comments['attack'],predict).ravel()\n",
    "\n",
    "print('precision recall:',precision_recall)\n",
    "print('true neg: ',tn,' false pos: ',fp,' false neg: ',fn,' true pos: ',tp)\n",
    "print('-----------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation to choose the best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "Time taken 216.67947006225586 seconds \n",
      "Accuracy: 0.9623 (+/- 0.0081)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Time taken 237.87252974510193 seconds \n",
      "Accuracy: 0.9508 (+/- 0.0073)\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Time taken 222.55188393592834 seconds \n",
      "Accuracy: 0.8381 (+/- 0.0185)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Time taken 377.7106149196625 seconds \n",
      "Accuracy: 0.8729 (+/- 0.0179)\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=1600, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "Time taken 250.28588223457336 seconds \n",
      "Accuracy: 0.9159 (+/- 0.0089)\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='modified_huber', max_iter=1600,\n",
      "       n_iter=None, n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "Time taken 263.6492209434509 seconds \n",
      "Accuracy: 0.9594 (+/- 0.0074)\n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      max_iter=1600, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
      "      shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "Time taken 238.44788074493408 seconds \n",
      "Accuracy: 0.9426 (+/- 0.0100)\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "Time taken 34747.747888326645 seconds \n",
      "Accuracy: 0.9379 (+/- 0.0100)\n"
     ]
    }
   ],
   "source": [
    "# Used training and dev set for choosing best classifier\n",
    "# Making use of development set ensured more data for the classifier to learn. \n",
    "# This is the 2nd optimization technique used. \n",
    "\n",
    "train_all_classifiers = comments.query(\"split=='train' | split =='dev'\")\n",
    "\n",
    "# The ML classifiers used are LinearSVC, Logistic Regression, MultiNomial NB, \n",
    "# Random Forest Classifier, Stochastic Gradient Descent, Perceptron and Multi Layer Perceptron\n",
    "# The best result for each classifer is shown below. \n",
    "# I found LinearSVC to be the best classifier among all\n",
    "clf_list = [\n",
    "            LinearSVC(),\n",
    "            LogisticRegression(),\n",
    "            MultinomialNB(),\n",
    "            RandomForestClassifier(),\n",
    "            SGDClassifier(loss='log',max_iter=1600,tol=1e-3),# SGD classifier requires passing of paramters like\n",
    "                                                             # max_iter and tol. \n",
    "            SGDClassifier(loss='modified_huber',max_iter=1600,tol=1e-3),\n",
    "            Perceptron(max_iter=1600,tol=1e-3),# Perceptron classifier requires passing of parameters max_iter & tol\n",
    "            MLPClassifier()\n",
    "            ]\n",
    "# features include - unigram and bigrams of words or chars. Adding both improved the performance of the code\n",
    "# so included both in the final code\n",
    "for classifier in clf_list:\n",
    "    start_time = time.time()\n",
    "    print(classifier)\n",
    "    clf = Pipeline([\n",
    "        ('vect', FeatureUnion([ \n",
    "            # Applied a combination of char and word tokenization using CountVectorizer and TfidfVectorizer\n",
    "            # After trial and testing applied max_feature as 75000, \n",
    "            # decode_error when set to 'replace'/'ignore' performed better than 'strict' \n",
    "            # This is the 3rd optimization technique applied.\n",
    "            ('count',CountVectorizer(max_features = 75000, ngram_range = (1,2),analyzer='word',\n",
    "                                     decode_error='replace')),\n",
    "            ('count1',CountVectorizer(max_features = 75000, ngram_range = (1,2),analyzer='char',\n",
    "                                     decode_error='replace')),\n",
    "            ('tfvect',TfidfVectorizer(max_features = 75000,norm = 'l2',analyzer='word',\n",
    "                                    decode_error='replace')),\n",
    "            ('tfvect1',TfidfVectorizer(max_features = 75000,norm = 'l2',analyzer='char',\n",
    "                                      decode_error='ignore'))\n",
    "        ])),\n",
    "        ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "        ('clf',  classifier)])\n",
    "    # Cross validation score was calculated for each classifer with the scoring parameter as 'roc_auc'\n",
    "    # cv=5 i.e. a K fold cross validation was performed with k as 5\n",
    "    # This is the 4th optimization technique applied. \n",
    "    scores=cross_val_score(clf, train_all_classifiers['comment'], train_all_classifiers['attack'], cv=5, scoring='roc_auc')\n",
    "    # time taken by each classifier was monitored\n",
    "    print(\"Time taken %s seconds \" % (time.time() - start_time))\n",
    "    # cross validation score with standard deviation is used to find the best classifier\n",
    "    print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on train set:\n",
      "\n",
      "{'clf__C': 0.4, 'clf__loss': 'squared_hinge', 'clf__random_state': 37, 'clf__tol': 0.001}\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.956 (+/-0.006) for {'clf__C': 0.4, 'clf__loss': 'hinge', 'clf__random_state': 37, 'clf__tol': 0.0001}\n",
      "0.956 (+/-0.006) for {'clf__C': 0.4, 'clf__loss': 'hinge', 'clf__random_state': 37, 'clf__tol': 0.001}\n",
      "0.956 (+/-0.006) for {'clf__C': 0.4, 'clf__loss': 'hinge', 'clf__random_state': 67, 'clf__tol': 0.0001}\n",
      "0.956 (+/-0.006) for {'clf__C': 0.4, 'clf__loss': 'hinge', 'clf__random_state': 67, 'clf__tol': 0.001}\n",
      "0.961 (+/-0.004) for {'clf__C': 0.4, 'clf__loss': 'squared_hinge', 'clf__random_state': 37, 'clf__tol': 0.0001}\n",
      "0.961 (+/-0.004) for {'clf__C': 0.4, 'clf__loss': 'squared_hinge', 'clf__random_state': 37, 'clf__tol': 0.001}\n",
      "0.961 (+/-0.004) for {'clf__C': 0.4, 'clf__loss': 'squared_hinge', 'clf__random_state': 67, 'clf__tol': 0.0001}\n",
      "0.961 (+/-0.004) for {'clf__C': 0.4, 'clf__loss': 'squared_hinge', 'clf__random_state': 67, 'clf__tol': 0.001}\n",
      "0.957 (+/-0.006) for {'clf__C': 0.6, 'clf__loss': 'hinge', 'clf__random_state': 37, 'clf__tol': 0.0001}\n",
      "0.957 (+/-0.006) for {'clf__C': 0.6, 'clf__loss': 'hinge', 'clf__random_state': 37, 'clf__tol': 0.001}\n",
      "0.957 (+/-0.006) for {'clf__C': 0.6, 'clf__loss': 'hinge', 'clf__random_state': 67, 'clf__tol': 0.0001}\n",
      "0.957 (+/-0.006) for {'clf__C': 0.6, 'clf__loss': 'hinge', 'clf__random_state': 67, 'clf__tol': 0.001}\n",
      "0.960 (+/-0.004) for {'clf__C': 0.6, 'clf__loss': 'squared_hinge', 'clf__random_state': 37, 'clf__tol': 0.0001}\n",
      "0.960 (+/-0.004) for {'clf__C': 0.6, 'clf__loss': 'squared_hinge', 'clf__random_state': 37, 'clf__tol': 0.001}\n",
      "0.960 (+/-0.004) for {'clf__C': 0.6, 'clf__loss': 'squared_hinge', 'clf__random_state': 67, 'clf__tol': 0.0001}\n",
      "0.960 (+/-0.004) for {'clf__C': 0.6, 'clf__loss': 'squared_hinge', 'clf__random_state': 67, 'clf__tol': 0.001}\n",
      "0.960 (+/-0.004) for {'clf__C': 0.5, 'clf__tol': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full training set.\n",
      "The scores are computed on the full training set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.95      0.99      0.97     20422\n",
      "       True       0.92      0.62      0.74      2756\n",
      "\n",
      "avg / total       0.95      0.95      0.94     23178\n",
      "\n",
      "\n",
      "{'C': 0.4, 'loss': 'squared_hinge', 'random_state': 37, 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# This cell shows the grid search operation implemented on the best classifier found previously. \n",
    "# After the best params are found from the grid search operation, these are applied on the classifier \n",
    "# The classifier is then used to predict on the test data set\n",
    "# Classification report is then generated on the predicted labels.\n",
    "# The ROC_AUC score, confusion matrix and Precison ,Recall,F1 score and support is also included below\n",
    "\n",
    "# for the grid search operation we only use training set samples\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "\n",
    "# Hyper parameters tuned for linear SVM are C, tol, loss and random_state\n",
    "# Accuracy percentage before applying hyperparameter tuning was = 95.6%\n",
    "# Accuracy percentage after applying hyperparameter tuning is = 96.6%\n",
    "# % difference between accuracies = 1 %\n",
    "# The tuned hyperparameters are : {'C': 0.4, 'loss': 'squared_hinge', 'random_state': 37, 'tol': 0.001}\n",
    "\n",
    "# params list for the grid search operation\n",
    "params = [{'clf__C':[0.4,0.6], # C - penalty factor for error term\n",
    "           'clf__tol':[1e-4,1e-3], # tol - tolerance for stopping criteria\n",
    "           'clf__loss':('hinge','squared_hinge'), # loss function - hinge is the standard SVM loss & \n",
    "                                                  # squared hinge is its sqaure\n",
    "          'clf__random_state':[37,67]}, # random state -The seed of the pseudo random number generator \n",
    "                                        # to use when shuffling the data.\n",
    "          {'clf__C':[0.5],\n",
    "           'clf__tol':[1e-4]}]\n",
    "clf = Pipeline([\n",
    "        # Feature Union of the previously used combination of CountVectorizer and TfIdfVectorizer\n",
    "        # Applied sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
    "        ('vect', FeatureUnion([\n",
    "            ('count',CountVectorizer(max_features = 75000, ngram_range = (1,2),analyzer='word',\n",
    "                                     decode_error='replace')),\n",
    "            ('count1',CountVectorizer(max_features = 75000, ngram_range = (1,2),analyzer='char',\n",
    "                                     decode_error='replace')),\n",
    "            ('tfvect',TfidfVectorizer(max_features = 75000,norm = 'l2',analyzer='word',\n",
    "                                    decode_error='replace',sublinear_tf=True)),\n",
    "            ('tfvect1',TfidfVectorizer(max_features = 75000,norm = 'l2',analyzer='char',\n",
    "                                      decode_error='ignore',sublinear_tf=True))\n",
    "        ])),\n",
    "        ('tfidf', TfidfTransformer(norm = 'l2',sublinear_tf=True)),\n",
    "        # Used LinearSVC as the classifier here as it showed the best result on the previous cell\n",
    "        ('clf',  LinearSVC())])\n",
    "# Grid Search function applied on the classifier with it's params list to choose from\n",
    "# scoring parameter is set to ROC_AUC to maintain uniformity across comparisions\n",
    "clf=GridSearchCV(clf, params,scoring='roc_auc')\n",
    "# The model learns on the training dataset \n",
    "clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "print(\"Best parameters set found on train set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on training set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full training set.\")\n",
    "print(\"The scores are computed on the full training set.\")\n",
    "print()\n",
    "# used the trained model to predit on the test data set\n",
    "y_true, y_pred = test_comments['attack'], clf.predict(test_comments['comment'])\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "best_params = {}\n",
    "for key in clf.best_params_:\n",
    "    best_params[key[5:]] = clf.best_params_[key]\n",
    "    \n",
    "print(best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on train set:\n",
      "\n",
      "{'clf__tol': 0.001, 'clf__random_state': 37, 'clf__max_iter': 2000, 'clf__loss': 'squared_hinge', 'clf__C': 0.4}\n",
      "\n",
      "Randomized Search scores on training set:\n",
      "\n",
      "0.957 (+/-0.006) for {'clf__tol': 0.001, 'clf__random_state': 37, 'clf__max_iter': 2000, 'clf__loss': 'hinge', 'clf__C': 0.6}\n",
      "0.960 (+/-0.004) for {'clf__tol': 0.0001, 'clf__random_state': 37, 'clf__max_iter': 2000, 'clf__loss': 'squared_hinge', 'clf__C': 0.6}\n",
      "0.957 (+/-0.006) for {'clf__tol': 0.001, 'clf__random_state': 67, 'clf__max_iter': 1500, 'clf__loss': 'hinge', 'clf__C': 0.6}\n",
      "0.956 (+/-0.006) for {'clf__tol': 0.0001, 'clf__random_state': 37, 'clf__max_iter': 2000, 'clf__loss': 'hinge', 'clf__C': 0.4}\n",
      "0.957 (+/-0.006) for {'clf__tol': 0.001, 'clf__random_state': 67, 'clf__max_iter': 2000, 'clf__loss': 'hinge', 'clf__C': 0.6}\n",
      "0.961 (+/-0.004) for {'clf__tol': 0.0001, 'clf__random_state': 37, 'clf__max_iter': 1500, 'clf__loss': 'squared_hinge', 'clf__C': 0.4}\n",
      "0.956 (+/-0.006) for {'clf__tol': 0.001, 'clf__random_state': 67, 'clf__max_iter': 2000, 'clf__loss': 'hinge', 'clf__C': 0.4}\n",
      "0.960 (+/-0.004) for {'clf__tol': 0.001, 'clf__random_state': 67, 'clf__max_iter': 2000, 'clf__loss': 'squared_hinge', 'clf__C': 0.6}\n",
      "0.961 (+/-0.004) for {'clf__tol': 0.001, 'clf__random_state': 37, 'clf__max_iter': 2000, 'clf__loss': 'squared_hinge', 'clf__C': 0.4}\n",
      "0.956 (+/-0.006) for {'clf__tol': 0.0001, 'clf__random_state': 67, 'clf__max_iter': 1500, 'clf__loss': 'hinge', 'clf__C': 0.4}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full training set.\n",
      "The scores are computed on the full training set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.95      0.99      0.97     20422\n",
      "       True       0.92      0.62      0.74      2756\n",
      "\n",
      "avg / total       0.95      0.95      0.94     23178\n",
      "\n",
      "\n",
      "{'tol': 0.001, 'random_state': 37, 'max_iter': 2000, 'loss': 'squared_hinge', 'C': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# for random search operation we only use training set samples\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "# Hyper parameters tuned for linear SVM are C, tol, loss ,random_state & max_iter\n",
    "# Accuracy percentage before applying hyperparameter tuning was = 95.6%\n",
    "# Accuracy percentage after applying hyperparameter tuning is = 96.6%\n",
    "# % difference between accuracies =  1%\n",
    "# The tuned hyperparameters are : {'C': 0.4, 'loss': 'squared_hinge', 'random_state': 37, 'tol': 0.0001, \n",
    "#                                   'max_iter'=2000}\n",
    "\n",
    "# params dictionary for the random search operation\n",
    "params = {'clf__C':[0.4,0.6], # C - penalty factor for error term\n",
    "          'clf__tol':[1e-4,1e-3], # tol - tolerance for stopping criteria\n",
    "          'clf__loss':('hinge','squared_hinge'), # loss function - hinge is the standard SVM loss & \n",
    "                                                  # squared hinge is its sqaure\n",
    "          'clf__random_state':[37,67], # random state -The seed of the pseudo random number generator \n",
    "                                        # to use when shuffling the data.\n",
    "          'clf__max_iter':[1500,2000]} # The maximum number of iterations to be run.\n",
    "clf = Pipeline([\n",
    "        # Feature Union of the previously used combination of CountVectorizer and TfIdfVectorizer\n",
    "        # Applied sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
    "        ('vect', FeatureUnion([\n",
    "            ('count',CountVectorizer(max_features = 75000, ngram_range = (1,2),analyzer='word',\n",
    "                                     decode_error='replace')),\n",
    "            ('count1',CountVectorizer(max_features = 75000, ngram_range = (1,2),analyzer='char',\n",
    "                                     decode_error='replace')),\n",
    "            ('tfvect',TfidfVectorizer(max_features = 75000,norm = 'l2',analyzer='word',\n",
    "                                    decode_error='replace',sublinear_tf=True)),\n",
    "            ('tfvect1',TfidfVectorizer(max_features = 75000,norm = 'l2',analyzer='char',\n",
    "                                      decode_error='ignore',sublinear_tf=True))\n",
    "        ])),\n",
    "        ('tfidf', TfidfTransformer(norm = 'l2',sublinear_tf=True)),\n",
    "        # Used LinearSVC as the classifier here as it showed the best result on the previous cell\n",
    "        ('clf',  LinearSVC())])\n",
    "# Random Search function applied on the classifier with it's params dictionary to choose from\n",
    "# scoring parameter is set to ROC_AUC to maintain uniformity across comparisions\n",
    "clf=RandomizedSearchCV(clf, param_distributions=params,scoring='roc_auc',return_train_score=True)\n",
    "# The model learns on the training dataset \n",
    "clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "print(\"Best parameters set found on train set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Randomized Search scores on training set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full training set.\")\n",
    "print(\"The scores are computed on the full training set.\")\n",
    "print()\n",
    "# used the trained model to predit on the test data set\n",
    "y_true, y_pred = test_comments['attack'], clf.predict(test_comments['comment'])\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "best_params = {}\n",
    "for key in clf.best_params_:\n",
    "    best_params[key[5:]] = clf.best_params_[key]\n",
    "    \n",
    "print(best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.96      0.99      0.97     20422\n",
      "       True       0.89      0.66      0.76      2756\n",
      "\n",
      "avg / total       0.95      0.95      0.95     23178\n",
      "\n",
      "\n",
      "Test ROC AUC: 0.966\n",
      "precision recall: (0.9476515491220501, 0.9497368193977047, 0.9465097793283376, None)\n",
      "true neg:  20189  false pos:  233  false neg:  932  true pos:  1824\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "###### This cell demonstrates the performance of Linear SVC along with it's tuned parameters applied to \n",
    "# test set for prediction purpose. \n",
    "# Multiple performance metrics are captured below on the learnt classifier\n",
    "# Looking at Confusion matrix we can tell how many of the true positives where classified correctly from\n",
    "# the test set. The classification report gives the Precision, Recall, F1 score and support values from the\n",
    "# test set. This gives an idea of how well the classifier performed. \n",
    "# Cross Validation has been previously applied to select the best classifier among the list.\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "\n",
    "clf = Pipeline([\n",
    "        # Feature Union of the previously used combination of CountVectorizer and TfIdfVectorizer\n",
    "        # Applied sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
    "        ('vect', FeatureUnion([\n",
    "            ('count',CountVectorizer(max_features = 75000, ngram_range = (1,2),analyzer='word',\n",
    "                                     decode_error='replace')),\n",
    "            ('count1',CountVectorizer(max_features = 75000, ngram_range = (1,2),analyzer='char',\n",
    "                                     decode_error='replace')),\n",
    "            ('tfvect',TfidfVectorizer(max_features = 75000,norm = 'l2',analyzer='word',\n",
    "                                    decode_error='replace',sublinear_tf=True)),\n",
    "            ('tfvect1',TfidfVectorizer(max_features = 75000,norm = 'l2',analyzer='char',\n",
    "                                      decode_error='ignore',sublinear_tf=True))\n",
    "        ])),\n",
    "        ('tfidf', TfidfTransformer(norm = 'l2',sublinear_tf=True)),\n",
    "        # for the purpose of using roc_auc_score function on the learnt classifier, ClaiberatedClassifierCV() \n",
    "        # is used on LinearSVM along with its best params list\n",
    "        # This was required because by default LinearSVM does not have predict_proba() function\n",
    "        # Used LinearSVC as the classifier here as it showed the best result on the previous cell\n",
    "        ('clf',  CalibratedClassifierCV(LinearSVC(tol= 0.001, random_state= 37, max_iter= 2000, loss= 'squared_hinge', C= 0.4)))])\n",
    "\n",
    "clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "# Claculation of Performance Metric : roc_auc_score\n",
    "auc = roc_auc_score(test_comments['attack'], clf.predict_proba(test_comments['comment'])[:, 1])\n",
    "predict = clf.predict(test_comments['comment'])\n",
    "# Claculation of Performance Metric : precision_recall\n",
    "precision_recall=precision_recall_fscore_support(test_comments['attack'], predict, average='weighted')\n",
    "# Claculation of Performance Metric : confusion_matrix\n",
    "tn, fp, fn, tp=confusion_matrix(test_comments['attack'],predict).ravel()\n",
    "y_true, y_pred = test_comments['attack'], clf.predict(test_comments['comment'])\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print('Test ROC AUC: %.3f' %auc)\n",
    "print('precision recall:',precision_recall)\n",
    "print('true neg: ',tn,' false pos: ',fp,' false neg: ',fn,' true pos: ',tp)\n",
    "print('-----------------------------------------------------------------------------------------')\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting facts learnt :  \n",
    "1. Preprocessing and data cleanup has a great impact on the performance of any classifier.   \n",
    "   Noise reduction in the data leads to better training of the model. Thus giving a better result   \n",
    "   on the test data!  \n",
    "2. GridSearchCV,RandomizedSearchCV are useful functions to find out the best parameters for any classifier    \n",
    "3. Random forest has the power to handle large data set with higher dimensionality. It can handle thousands\n",
    "   of input variables and identify most significant variables. It surely does a good job at classification \n",
    "   but not as good as for regression problem as it does not give precise continuous nature predictions.\n",
    "4. SGD can be successfully applied to large-scale and sparse machine learning problems often \n",
    "   encountered in text classification and natural language processing. But SGD requires a number of \n",
    "   hyperparameters such as the regularization parameter and the number of iterations.\n",
    "5. MLP cannot guarantee that the that the minima it stops at during training is the global minima. \n",
    "   The MLP algorithm can, therefore, get stuck in a local minima.Another disadvantage is is that \n",
    "   the number of Hidden Neurons must be set by the user, setting this value too low may result  \n",
    "   in the MLP model underfitting while setting this value too high may result in overfitting. \n",
    "\n",
    "# Challenges faced:\n",
    "1. Finding the list of parameters that should be provided to grid search/randomized search operation.   \n",
    "   This is a time consuming process as it needs carefully trials for various values of   \n",
    "   the possible parameters to decide which suits best for the experiment.  \n",
    "2. Finding the right combination of the features in the feature union function provided for   \n",
    "   tokenization of text. This was again achieved on a trial and error basis and hence was an exhaustive process.\n",
    "\n",
    "# Final Metrics \n",
    "   Test ROC AUC score: 0.966    \n",
    "   precision recall: (0.8867282450170151, 0.6618287373004355, 0.7579472262622066, None)  \n",
    "   true neg:  20189  false pos:  233  false neg:  932  true pos:  1824  \n",
    "   LinearSVC model gave the above metrics    \n",
    "\n",
    "   Original strawman code had ROC AUC score of 0.957  \n",
    "   Thus LinearSVM improved the ROC AUC score by 0.9 units     \n",
    "\n",
    "# Classification Report - \n",
    "    precision    recall  f1-score   support  \n",
    "      \n",
    "    False       0.95      0.99      0.97     20422  \n",
    "    True       0.92      0.62      0.74      2756  \n",
    "  \n",
    "    avg / total       0.95      0.95      0.94     23178  \n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
